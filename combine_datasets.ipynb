{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of your dataframe\n",
    "df2 = df.copy()\n",
    "# make a list column names\n",
    "cols = df2.columns.tolist()\n",
    "# replace space with _\n",
    "cols = [col.replace(' ', '_') for col in cols]\n",
    "# reassign new column names to dataframe\n",
    "df2.columns = cols\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = df2.columns.str.lower()\n",
    "df2.rename(columns={\"Bike_#\": \"Bike_num\"}, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just gives us a mask - tells us True or False whether each row fit's the condition.\n",
    "df['length'] <= 0.4\n",
    "# To use a mask, we actually have to use it to index into the DataFrame (using square brackets). \n",
    "df[df['length'] <= 0.4]\n",
    "# Okay, this is cool. What if I wanted a slightly more complicated query...\n",
    "df[(df['length'] <= 0.4) & (df['sex'] == 'F')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we try to groupby the sex, let's check how many different values this feature can have \n",
    "df['sex'].unique()\n",
    "# we can also see the count of different values with this command\n",
    "df['sex'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"start_station\"].value_counts()\n",
    "df2\n",
    "df2.groupby(\"start_station\").count().sort_values(\"trip_id\", ascending=False)\n",
    "df2[\"start_station\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_obj = df.groupby('sex')\n",
    "# \n",
    "groupby_obj.mean(), max(), count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(\"subscription_type\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with `.eval()` we can create new columns\n",
    "df.eval('age_2 = nr_rings + 1.5', inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df_example.drop(\"Ubaid\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows\n",
    "df_example.drop(0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the addition of the inplace argument here. \n",
    "# if you try to fill nans will some value: the first argument is the inserted value\n",
    "df.fillna(-1, inplace=True)\n",
    "# dropna() will drop the whole row, if nans are present\n",
    "df.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_2 = iris[iris.species == \"Iris-setosa\"]\n",
    "iris_2.head().reset_index().sort_values(\"petal_area\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect duplicates\n",
    "thefts_df[thefts_df.duplicated(keep=False)].sort_values(by=['tatzeit_anfang_datum', 'schadenshoehe']).tail(6)\n",
    "thefts_df\n",
    "# the specifications of the duplicates indicate that they are implausible, so we drop them.\n",
    "# drop duplicates (rows by default)\n",
    "thefts_df.drop_duplicates(inplace=True)\n",
    "thefts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique values holds the column of the attempts?\n",
    "thefts_df.versuch.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining columns of another DataFrame using the join() method.\n",
    "join_df = thefts_df.join(biketype_dummies)\n",
    "join_df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
